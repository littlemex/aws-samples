{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5789bc3-b1ae-42c7-94a8-2ef4f89946fc",
   "metadata": {},
   "source": [
    "# Lab 4: Persistence and Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b724f8",
   "metadata": {},
   "source": [
    "## 環境設定\n",
    "\n",
    "エージェント環境の構築から始めます。このプロセスには、必要な環境変数の読み込み、必要なモジュールのインポート、Tavilyサーチツールの初期化、エージェントの状態の定義、そして最終的にエージェントの構築が含まれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-09 19:07:56,410] p1185132 {utils.py:66} INFO - TAVILY_API_KEY variable correctly retrieved from the .env file.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "\n",
    "# ローカルモジュールのインポート\n",
    "dir_current = os.path.abspath(\"\")\n",
    "dir_parent = os.path.dirname(dir_current)\n",
    "if dir_parent not in sys.path:\n",
    "    sys.path.append(dir_parent)\n",
    "from utils import utils\n",
    "\n",
    "# 基本設定\n",
    "logger = utils.set_logger()  # ロガーの設定\n",
    "pp = utils.set_pretty_printer()  # 整形出力用のプリンターを設定\n",
    "\n",
    "# .envファイルまたはSecret Managerから環境変数を読み込む\n",
    "_ = load_dotenv(\"../.env\")\n",
    "aws_region = os.getenv(\"AWS_REGION\")  # AWS地域を環境変数から取得\n",
    "tavily_ai_api_key = utils.get_tavily_api(\"TAVILY_API_KEY\", aws_region)  # Tavily APIキーを取得\n",
    "\n",
    "# Bedrockの設定\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={\"max_attempts\": 0})  # タイムアウトと再試行の設定\n",
    "\n",
    "# Bedrockランタイムクライアントの作成\n",
    "bedrock_rt = boto3.client(\"bedrock-runtime\", region_name=aws_region, config=bedrock_config)\n",
    "\n",
    "# 利用可能なモデルを確認するためのBedrockクライアントの作成\n",
    "bedrock = boto3.client(\"bedrock\", region_name=aws_region, config=bedrock_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da06a64f-a2d5-4a66-8090-9ada0930c684",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1185132/4289725543.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tool = TavilySearchResults(max_results=2)\n"
     ]
    }
   ],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c989adc7",
   "metadata": {},
   "source": [
    "## 永続性の実装\n",
    "\n",
    "次に、永続性の実装に注目します。これを達成するために、LangGraphにおけるチェックポインターの概念を導入します。チェックポインターの機能は、エージェントの処理グラフの各ノードの後および間に状態のスナップショットを作成することです。\n",
    "\n",
    "#リソース LangGraphの機能と使用法についてより包括的に理解するには、公式のLangGraphドキュメントを参照してください。\n",
    "\n",
    "この実装では、チェックポインターとしてSQLiteセーバーを使用します。この軽量なソリューションは、組み込みのデータベースエンジンであるSQLiteを活用しています。このデモでは、インメモリデータベースを使用していますが、本番環境では外部データベースに接続するように簡単に適応できることに注意することが重要です。LangGraphは、より堅牢なデータベースシステムが必要なシナリオのために、RedisやPostgresなどの他の永続性ソリューションもサポートしています。\n",
    "\n",
    "チェックポインターを初期化した後、それを`graph.compile`メソッドに渡します。エージェントを強化して`checkpointer`パラメータを受け入れるようにし、それをメモリオブジェクトに設定しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01441e5e",
   "metadata": {},
   "source": [
    "## エージェントクラス：詳細な検証\n",
    "\n",
    "`Agent`クラスは私たちの実装の基盤として機能し、言語モデル（Claude）、ツール（Tavilyサーチなど）、および全体的な会話の流れの間の相互作用を調整します。その主要なコンポーネントを検討しましょう：\n",
    "\n",
    "1. `__init__`メソッド：このイニシャライザはモデル、ツール、チェックポインター、およびオプションのシステムメッセージでエージェントを設定します。エージェントの動作を定義する状態グラフを構築します。\n",
    "\n",
    "2. `call_bedrock`メソッド：このメソッドはAmazon Bedrockを介してClaudeモデルを呼び出す責任があります。現在の状態（メッセージ）を処理し、モデルの応答を返します。\n",
    "\n",
    "3. `exists_action`メソッド：このメソッドは、モデルからの最新のメッセージに何らかのツール呼び出し（実行されるアクション）が含まれているかどうかを評価します。\n",
    "\n",
    "4. `take_action`メソッド：このメソッドはモデルによって指定されたツール呼び出しを実行し、結果を返します。\n",
    "\n",
    "`Agent`クラスは会話の流れを管理するために`StateGraph`を利用し、明確で管理しやすい構造を維持しながら複雑な相互作用を可能にします。この設計選択により、永続性とストリーミング機能の実装が容易になります。\n",
    "\n",
    "## ストリーミングの実装\n",
    "\n",
    "エージェントが設定されたので、ストリーミング機能を実装できます。考慮すべきストリーミングの主な側面は2つあります：\n",
    "\n",
    "1. メッセージストリーミング：これには、次のアクションを決定するAIメッセージやアクションの結果を表す観察メッセージなど、個々のメッセージのストリーミングが含まれます。\n",
    "\n",
    "2. トークンストリーミング：これには、生成される際の言語モデルの応答の各トークンのストリーミングが含まれます。\n",
    "\n",
    "まず、メッセージストリーミングを実装します。人間のメッセージ（例：「SFの天気はどうですか？」）を作成し、スレッド設定を導入します。このスレッド設定は、永続的なチェックポインター内で複数の会話を同時に管理するために重要であり、複数のユーザーにサービスを提供する本番アプリケーションには必須です。\n",
    "\n",
    "`invoke`の代わりに`stream`メソッドを使用してグラフを呼び出し、メッセージ辞書とスレッド設定を渡します。これにより、状態のリアルタイム更新を表すイベントのストリームが返されます。\n",
    "\n",
    "実行すると、結果のストリームが観察されます：まず、取るべきアクションを決定するClaudeからのAIメッセージ、次にTavilyサーチ結果を含むツールメッセージ、そして最後に、最初のクエリに答えるClaudeからの別のAIメッセージです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 574
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        # システムメッセージを設定\n",
    "        self.system = system\n",
    "        # 状態グラフを初期化\n",
    "        graph = StateGraph(AgentState)\n",
    "        # LLMノードを追加（Bedrockを呼び出す）\n",
    "        graph.add_node(\"llm\", self.call_bedrock)\n",
    "        # アクションノードを追加（ツールを実行する）\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        # 条件付きエッジを追加：ツール呼び出しがあればアクションへ、なければ終了\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        # アクションからLLMへのエッジを追加（ツール実行後に再びLLMへ）\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        # エントリーポイントをLLMに設定\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        # チェックポインターを使用してグラフをコンパイル\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        # ツールを名前でアクセスできるように辞書に格納\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        # モデルにツールをバインド\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_bedrock(self, state: AgentState):\n",
    "        # 現在のメッセージ履歴を取得\n",
    "        messages = state[\"messages\"]\n",
    "        # システムメッセージがあれば先頭に追加\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        # モデルを呼び出して応答を取得\n",
    "        message = self.model.invoke(messages)\n",
    "        # 応答をメッセージリストに追加して返す\n",
    "        return {\"messages\": [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        # 最新のメッセージを取得\n",
    "        result = state[\"messages\"][-1]\n",
    "        # ツール呼び出しがあるかどうかを確認\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        # 最新のメッセージからツール呼び出しを取得\n",
    "        tool_calls = state[\"messages\"][-1].tool_calls\n",
    "        results = []\n",
    "        # 各ツール呼び出しを実行\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            # ツールを名前で呼び出し、引数を渡して実行\n",
    "            result = self.tools[t[\"name\"]].invoke(t[\"args\"])\n",
    "            # 結果をツールメッセージとして追加\n",
    "            results.append(ToolMessage(tool_call_id=t[\"id\"], name=t[\"name\"], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        # ツール実行結果をメッセージリストとして返す\n",
    "        return {\"messages\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"あなたはスマートな研究アシスタントです。検索エンジンを使用して情報を調べてください。\\\n",
    "複数の呼び出しを行うことができます（同時または連続して）。\\\n",
    "何を求めているか確信がある場合にのみ、情報を検索してください。\\\n",
    "フォローアップの質問をする前に情報を調べる必要がある場合は、それも許可されています！\n",
    "\"\"\"\n",
    "\n",
    "model = ChatBedrockConverse(\n",
    "    client=bedrock_rt,\n",
    "    model=\"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    ")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# 「サンフランシスコの天気は？」という質問を含む人間のメッセージを作成\n",
    "messages = [HumanMessage(content=\"サンフランシスコの天気は？\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content=[{'type': 'tool_use', 'name': 'tavily_search_results_json', 'input': {'query': 'サンフランシスコ 現在の天気'}, 'id': 'tooluse_cvFg5jASQaKjge6ynQaIxA'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '66f12951-b481-4914-950f-9c30e12edc99', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Jul 2025 19:19:36 GMT', 'content-type': 'application/json', 'content-length': '328', 'connection': 'keep-alive', 'x-amzn-requestid': '66f12951-b481-4914-950f-9c30e12edc99'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1823]}, 'model_name': 'us.anthropic.claude-3-5-haiku-20241022-v1:0'}, id='run--f46242e8-45bf-42d0-9392-74875fb8204c-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'サンフランシスコ 現在の天気'}, 'id': 'tooluse_cvFg5jASQaKjge6ynQaIxA', 'type': 'tool_call'}], usage_metadata={'input_tokens': 496, 'output_tokens': 71, 'total_tokens': 567, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'サンフランシスコ 現在の天気'}, 'id': 'tooluse_cvFg5jASQaKjge6ynQaIxA', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "[ToolMessage(content=\"[{'title': 'サンフランシスコの天気予報【アメリカ】 - ウェザーニュース', 'url': 'https://weathernews.jp/onebox/tenki/world/7/us/san-francisco/', 'content': '風邪予防指数\\\\n\\\\n乾燥指数\\\\n\\\\n予報精度向上の取り組み\\\\n\\\\n予報に関するよくある質問\\\\n\\\\nSORASHOP\\\\n\\\\nLabs Ch.\\\\n\\\\nマイソリューション\\\\n\\\\nThe Last 10-Second\\\\n\\\\n他メニュー\\\\n\\\\nサンフランシスコ\\\\n\\\\n# サンフランシスコの天気予報 現地時刻 6/4(水) 13時\\\\n\\\\n日\\\\n\\\\n時\\\\n\\\\n天気\\\\n\\\\n降水\\\\n\\\\n気温\\\\n\\\\n風\\\\n\\\\n4日(水)\\\\n\\\\n13\\\\n\\\\n0ミリ\\\\n\\\\n18℃\\\\n\\\\n5 m\\\\n\\\\n14\\\\n\\\\n0ミリ\\\\n\\\\n18℃\\\\n\\\\n5.7 m\\\\n\\\\n15\\\\n\\\\n0ミリ\\\\n\\\\n18℃\\\\n\\\\n5.9 m\\\\n\\\\n16\\\\n\\\\n0ミリ\\\\n\\\\n17℃\\\\n\\\\n5.7 m\\\\n\\\\n17\\\\n\\\\n0ミリ\\\\n\\\\n17℃\\\\n\\\\n5.5 m\\\\n\\\\n18\\\\n\\\\n0ミリ\\\\n\\\\n16℃\\\\n\\\\n5.3 m\\\\n\\\\n19\\\\n\\\\n0ミリ\\\\n\\\\n15℃\\\\n\\\\n5 m\\\\n\\\\n20\\\\n\\\\n0ミリ\\\\n\\\\n14℃\\\\n\\\\n4.7 m\\\\n\\\\n21\\\\n\\\\n0ミリ\\\\n\\\\n14℃\\\\n\\\\n4.5 m\\\\n\\\\n22\\\\n\\\\n0ミリ\\\\n\\\\n14℃\\\\n\\\\n4.3 m\\\\n\\\\n23\\\\n\\\\n0ミリ\\\\n\\\\n13℃\\\\n\\\\n4.4 m\\\\n\\\\n5日(木)\\\\n\\\\n0\\\\n\\\\n0ミリ\\\\n\\\\n13℃\\\\n\\\\n4.5 m\\\\n\\\\n1\\\\n\\\\n0ミリ\\\\n\\\\n13℃\\\\n\\\\n4.6 m\\\\n\\\\n2\\\\n\\\\n0ミリ\\\\n\\\\n13℃\\\\n\\\\n4.7 m\\\\n\\\\n3\\\\n\\\\n0ミリ\\\\n\\\\n13℃\\\\n\\\\n4.5 m\\\\n\\\\n4\\\\n\\\\n0ミリ\\\\n\\\\n13℃', 'score': 0.838376}, {'title': 'サンフランシスコ, CAの3日間の天気予報 - AccuWeather', 'url': 'https://www.accuweather.com/ja/us/san-francisco/94103/weather-forecast/347629', 'content': 'サンフランシスコ, CAの3日間の天気予報 | AccuWeather\\\\n\\\\n===============\\\\n\\\\n戻る\\\\n\\\\n[]( カリフォルニア州 ================== 51°F\\\\n\\\\n現在のロケーションを使う\\\\n\\\\n履歴\\\\n\\\\nサンフランシスコ カリフォルニア州 51°\\\\n\\\\n検索結果がありません。\\\\n\\\\n都市、郵便番号、または特定スポット名を検索してみてください。\\\\n\\\\n[](\\\\n\\\\n設定\\\\n\\\\nサンフランシスコ, カリフォルニア州の天気\\\\n\\\\n今日WinterCastローカル{stormName}トラッカー毎時毎日レーダーMinuteCast月間大気質健康・アクティビティ\\\\n\\\\n世界中\\\\n---\\\\n\\\\n### ハリケーン### 悪天候### レーダー&地図### ビデオ### ウィンターセンター\\\\n\\\\n今日 --毎時毎日レーダーMinuteCast月間大気質健康・アクティビティ\\\\n\\\\n現在の天気 ----- 0:40 51°F RealFeel® 48° おおむね曇り 詳細を表示する 風向 西南西 7 mph 突風 14 mph 大気質 普通\\\\n\\\\nサンフランシスコの気象レーダー画像\\\\n----------------- [...] 今日 5/25 Image 28 62°54° 低い雲、のち晴れ Image 29 おおむね曇り 0%月 5/26 Image 30 65°53° 低い雲、のち晴れ間 Image 31 晴れ 0%火 5/27 Image 32 65°54° おおむね晴れ Image 33 雲が増す 0%水 5/28 Image 34 62°53° 低く垂れ込めた雲 Image 35 おおむね曇り 0%木 5/29 Image 36 67°53° 晴れ Image 37 晴れ 0%金 5/30 Image 38 70°54° 晴れ Image 39 所により曇り 0%土 5/31 Image 40 65°56° おおむね曇り Image 41 低く垂れ込めた雲 0%日 6/1 Image 42 64°55° 晴れたり曇ったり Image 43 低く垂れ込めた雲 0%月 6/2 Image 44 64°55° 晴れたり曇ったり Image 45 低く垂れ込めた雲 0%火 6/3 Image 46 65°54° 低く垂れ込めた雲 Image 47 低く垂れ込めた雲 0%\\\\n\\\\n太陽と月\\\\n---- [...] 1時 Image 452° Image 5: rain drop0%2時 Image 652° Image 7: rain drop0%3時 Image 852° Image 9: rain drop0%4時 Image 1052° Image 11: rain drop0%5時 Image 1252° Image 13: rain drop0%6時 Image 1452° Image 15: rain drop0%7時 Image 1653° Image 17: rain drop0%8時 Image 1854° Image 19: rain drop0%9時 Image 2056° Image 21: rain drop0%10時 Image 2257° Image 23: rain drop0%11時 Image 2459° Image 25: rain drop0%12時 Image 2660° Image 27: rain drop0%\\\\n\\\\n毎日の予報\\\\n-----', 'score': 0.83678174}]\", name='tavily_search_results_json', tool_call_id='tooluse_cvFg5jASQaKjge6ynQaIxA')]\n",
      "[AIMessage(content='現在のサンフランシスコの天気は以下のようです：\\n\\n- 気温：約18℃（64-65°F）\\n- 天候：おおむね曇り\\n- 風：西南西の方向に約5-7 mph（時速8-11キロ）\\n- 降水確率：0%\\n\\n午後は気温が少し下がり、16-17℃くらいになる予報です。夜は13-14℃まで下がる見込みです。全体的に曇りがちで、雨の可能性は低いようです。\\n\\n何か他に知りたいことはありますか？', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'cfbedfa6-6ac8-4040-b62d-2802c89e54e5', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Jul 2025 19:19:49 GMT', 'content-type': 'application/json', 'content-length': '770', 'connection': 'keep-alive', 'x-amzn-requestid': 'cfbedfa6-6ac8-4040-b62d-2802c89e54e5'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [9439]}, 'model_name': 'us.anthropic.claude-3-5-haiku-20241022-v1:0'}, id='run--7746d8e4-3e38-4bbf-b04f-e3b38c6eebeb-0', usage_metadata={'input_tokens': 2410, 'output_tokens': 175, 'total_tokens': 2585, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070f625b",
   "metadata": {},
   "source": [
    "## 永続性の実証\n",
    "\n",
    "永続性の実装の効果を示すために、フォローアップの質問「LAではどうですか？」で会話を続けます。同じスレッドIDを使用することで、前回のやり取りからの連続性を確保します。Claudeはチェックポイントシステムによって提供される永続性のおかげで、私たちがまだ天気状況について問い合わせていることを理解し、コンテキストを維持します。\n",
    "\n",
    "スレッドIDの重要性をさらに強調するために、それを変更して「どちらが暖かいですか？」という質問をすることができます。元のスレッドIDでは、Claudeは正確に温度を比較できます。しかし、スレッドIDを変更すると、会話履歴にアクセスできなくなるため、Claudeはコンテキストを失います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content=[{'type': 'tool_use', 'name': 'tavily_search_results_json', 'input': {'query': '東京 現在の天気 気温'}, 'id': 'tooluse_eIfMJaYWQLaT2HIKNgHQCw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '6ea56c40-7ea6-4302-9c92-d31a90dc8c60', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Jul 2025 19:31:15 GMT', 'content-type': 'application/json', 'content-length': '429', 'connection': 'keep-alive', 'x-amzn-requestid': '6ea56c40-7ea6-4302-9c92-d31a90dc8c60'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1763]}, 'model_name': 'us.anthropic.claude-3-5-haiku-20241022-v1:0'}, id='run--a9545749-c54f-4bf3-9c90-51520a55288e-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': '東京 現在の天気 気温'}, 'id': 'tooluse_eIfMJaYWQLaT2HIKNgHQCw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4986, 'output_tokens': 68, 'total_tokens': 5054, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': '東京 現在の天気 気温'}, 'id': 'tooluse_eIfMJaYWQLaT2HIKNgHQCw', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content=\"[{'title': '東京都のアメダス実況(気温) - 日本気象協会 tenki.jp', 'url': 'https://tenki.jp/amedas/3/16/', 'content': '| 地点名 | 気温 (℃) | 降水量 (mm/h) | 風向 (16方位) | 風速 (m/s) | 日照時間 (分) | 積雪深 (cm) |\\\\n| --- | --- | --- | --- | --- | --- | --- |\\\\n| 東京 | 29.4 | 0.0 | 南南東 | 3.4 | 60 | --- |\\\\n| 江戸川臨海 | 28.3 | 0.0 | 南 | 6.0 | 60 | --- |\\\\n| 羽田 | 28.3 | 0.0 | 南 | 7.2 | --- | --- |\\\\n| 世田谷 | --- | 0.0 | --- | --- | --- | --- |\\\\n| 練馬 | 30.6 | 0.0 | 南東 | 1.1 | 57 | --- |\\\\n| 府中 | 31.4 | 0.0 | 南 | 3.3 | 47 | --- |\\\\n| 八王子 | 29.9 | 0.0 | 南 | 5.8 | 60 | --- |\\\\n| 青梅 | 30.0 | 0.0 | 南東 | 2.3 | 44 | --- | [...] # tenki.jp\\\\n\\\\n雨雲レーダー)\\\\n天気図\\\\nPM2.5分布予測\\\\n地震情報\\\\n日直予報士\\\\n梅雨入り・明け\\\\n\\\\n## 東京都のアメダス実況(気温)20日15:50現在\\\\n\\\\n気温\\\\n降水量\\\\n風向・風速\\\\n日照時間\\\\n積雪深\\\\n\\\\n雨雲レーダー\\\\n\\\\n雨雲レーダーを見る（東京都）\\\\n\\\\nLINEの友達追加\\\\n\\\\n### 東京都の今日のアメダスの記録(06月20日)20日15:00現在\\\\n\\\\n東京\\\\n\\\\n31.4℃/23.3℃\\\\n\\\\n(14:09)(03:52)\\\\n\\\\n0.0mm/日\\\\n\\\\n江戸川臨海\\\\n\\\\n30.4℃/24.5℃\\\\n\\\\n(14:00)(03:15)\\\\n\\\\n0.0mm/日\\\\n\\\\n羽田\\\\n\\\\n29.8℃/24.1℃\\\\n\\\\n(14:57)(03:59)\\\\n\\\\n0.0mm/日\\\\n\\\\n世田谷\\\\n\\\\n---/---\\\\n\\\\n(---)(---)\\\\n\\\\n0.0mm/日\\\\n\\\\n練馬\\\\n\\\\n32.1℃/23.5℃\\\\n\\\\n(14:23)(04:07)\\\\n\\\\n0.0mm/日\\\\n\\\\n### 東京都のアメダス実況', 'score': 0.69845337}, {'title': '今日・明日と14日間(2週間)の1時間ごとの天気予報 - Toshin.com - 東進', 'url': 'https://www.toshin.com/weather/detail?id=66124', 'content': '最低\\\\n\\\\n21℃\\\\n\\\\n降水量\\\\n\\\\n0.0mm\\\\n\\\\n湿度\\\\n\\\\n73%\\\\n\\\\n風速\\\\n\\\\n3m/s\\\\n\\\\n風向\\\\n\\\\n南\\\\n\\\\n最高\\\\n\\\\n28℃\\\\n\\\\n最低\\\\n\\\\n21℃\\\\n\\\\n降水量\\\\n\\\\n0.0mm\\\\n\\\\n湿度\\\\n\\\\n35%\\\\n\\\\n風速\\\\n\\\\n10m/s\\\\n\\\\n風向\\\\n\\\\n北西\\\\n\\\\n最高\\\\n\\\\n31℃\\\\n\\\\n最低\\\\n\\\\n25℃\\\\n\\\\n降水量\\\\n\\\\n0.0mm\\\\n\\\\n湿度\\\\n\\\\n43%\\\\n\\\\n風速\\\\n\\\\n7m/s\\\\n\\\\n風向\\\\n\\\\n南\\\\n\\\\n最高\\\\n\\\\n30℃\\\\n\\\\n最低\\\\n\\\\n24℃\\\\n\\\\n降水量\\\\n\\\\n0.0mm\\\\n\\\\n湿度\\\\n\\\\n44%\\\\n\\\\n風速\\\\n\\\\n5m/s\\\\n\\\\n風向\\\\n\\\\n東\\\\n\\\\n最高\\\\n\\\\n30℃\\\\n\\\\n最低\\\\n\\\\n24℃\\\\n\\\\n降水量\\\\n\\\\n0.0mm\\\\n\\\\n湿度\\\\n\\\\n85%\\\\n\\\\n風速\\\\n\\\\n5m/s\\\\n\\\\n風向\\\\n\\\\n北東\\\\n\\\\n最高\\\\n\\\\n21℃\\\\n\\\\n最低\\\\n\\\\n20℃\\\\n\\\\n天気アイコンの意味について\\\\n\\\\n# 東京の 雨雲レーダー\\\\n\\\\nクリックすると拡大します\\\\n\\\\n \\\\n\\\\n[Leaflet | 地理院タイル](/weather/rader?lat=35.678937777778&lng=139.76812194444)\\\\n\\\\n自宅の天気をピンポイントに登録する\\\\n\\\\n建物単位まで天気をピンポイント検索!\\\\n\\\\nピンポイント天気予報検索\\\\n\\\\n付近のGPS情報から検索\\\\n\\\\n現在地から付近の天気を検索 [...] - 東進ビジネススクール  \\\\n  大学生向け東進学力POS\\\\n\\\\n- 社会人対象\\\\n\\\\n- 東進ビジネススクール  \\\\n  社会人向け東進学力POS\\\\n\\\\nマイページ\\\\n\\\\n資料請求\\\\n\\\\n入学受付\\\\n\\\\n全国学校のお天気\\\\n\\\\n新規会員登録 ログイン 天気メールを設定する\\\\n\\\\n \\\\n\\\\nHome   >  東京都   >  千代田区   >  東京   >  14日間(2週間)の1時間ごとの天気予報\\\\n\\\\n   \\\\n\\\\n雨雲レーダー\\\\n\\\\n \\\\n\\\\n# 東京の天気\\\\n\\\\n6月5日 13:00発表\\\\n\\\\nリロードすると1時間ごとに更新されます。\\\\n\\\\n今日\\\\n\\\\n2025年\\\\n\\\\n6月5日(木)\\\\n\\\\n晴れ\\\\n\\\\n28℃/19℃\\\\n\\\\n降水確率\\\\n\\\\n0%\\\\n\\\\n明日\\\\n\\\\n2025年\\\\n\\\\n6月6日(金)\\\\n\\\\n晴れ\\\\n\\\\n28℃/18℃\\\\n\\\\n降水確率\\\\n\\\\n0%\\\\n\\\\n明日\\\\n\\\\n2025年\\\\n\\\\n6月6日(金)\\\\n\\\\n晴れ\\\\n\\\\n28℃/18℃\\\\n\\\\n降水確率\\\\n\\\\n0%\\\\n\\\\n2025年\\\\n\\\\n6月7日(土)\\\\n\\\\n晴れ時々曇\\\\n\\\\n26℃/19℃\\\\n\\\\n降水確率\\\\n\\\\n20%\\\\n\\\\n2025年\\\\n\\\\n6月7日(土)\\\\n\\\\n晴れ時々曇\\\\n\\\\n26℃/19℃\\\\n\\\\n降水確率\\\\n\\\\n20%\\\\n\\\\n2025年\\\\n\\\\n6月8日(日)\\\\n\\\\n時々曇り\\\\n\\\\n29℃/21℃\\\\n\\\\n降水確率 [...] | 26 | 25 | 25 | 24 | 24 | 24 | 24 | 25 | 26 | 27 | 28 | 29 | 30 | 30 | 30 | 30 | 29 | 29 | 28 | 27 | 27 | 26 | 26 | 26 |\\\\n| 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |\\\\n| 59 | 64 | 69 | 74 | 72 | 70 | 68 | 64 | 59 | 55 | 52 | 48 | 45 | 44 | 43 | 42 | 45 | 48 | 51 | 55 | 58 | 61 | 62 | 63 |\\\\n| 南西 | 南西 | 南西 | 南西 | 南西 | 南西 | 西 | 南西 | 南西 | 南西 | 南 | 南 | 南 | 南 | 南 | 南 | 南 | 南 | 南 | 南 | 南 | 南 | 東南 | 東 |', 'score': 0.64585793}]\", name='tavily_search_results_json', tool_call_id='tooluse_eIfMJaYWQLaT2HIKNgHQCw')]}\n",
      "{'messages': [AIMessage(content='東京の現在の天気は以下の通りです：\\n\\n- 気温：約29-31℃（非常に暑い）\\n- 天候：晴れ\\n- 風向：南または南南東\\n- 風速：3-7 m/s\\n- 降水量：0 mm\\n- 湿度：約40-70%\\n\\nサンフランシスコ（18℃）、ロサンゼルス（24℃）と比べて、東京は最も暑い状況です。真夏のような暑さで、快晴の天気となっています。\\n\\n何か他に知りたいことはありますか？', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'ca71dc13-14a4-4c38-bf14-2cd17c7061ad', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Jul 2025 19:31:29 GMT', 'content-type': 'application/json', 'content-length': '757', 'connection': 'keep-alive', 'x-amzn-requestid': 'ca71dc13-14a4-4c38-bf14-2cd17c7061ad'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [10916]}, 'model_name': 'us.anthropic.claude-3-5-haiku-20241022-v1:0'}, id='run--0f335701-96c9-478a-92d0-85e1ef7bf4e5-0', usage_metadata={'input_tokens': 7616, 'output_tokens': 176, 'total_tokens': 7792, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"東京はどうですか?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='現在の気温を比較すると：\\n\\n1. サンフランシスコ：約18℃\\n2. ロサンゼルス：約24℃\\n3. 東京：約29-31℃\\n\\n東京が最も暖かく、次にロサンゼルス、そしてサンフランシスコが最も涼しいです。具体的には、東京はロサンゼルスよりも約5-7℃、サンフランシスコよりも約11-13℃高温となっています。\\n\\nしたがって、東京が最も暖かい都市です。', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '7b5840fb-1974-47a8-916c-1dcd35a254a3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Jul 2025 19:31:47 GMT', 'content-type': 'application/json', 'content-length': '753', 'connection': 'keep-alive', 'x-amzn-requestid': '7b5840fb-1974-47a8-916c-1dcd35a254a3'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [6824]}, 'model_name': 'us.anthropic.claude-3-5-haiku-20241022-v1:0'}, id='run--3f08d03d-f424-40ef-80fa-7458375fe0c7-0', usage_metadata={'input_tokens': 7808, 'output_tokens': 165, 'total_tokens': 7973, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"どちらの方が暖かいですか?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='申し訳ありませんが、「どちらの」という具体的な対象が明確ではありません。比較したい2つのものについて、もう少し詳しく教えていただけますか？例えば、地域、気候、物、服、食べ物など、何と何を比較したいのでしょうか？具体的な情報をお聞かせください。', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '73045f3e-d24a-4375-b2ed-652107cccf75', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Jul 2025 19:32:40 GMT', 'content-type': 'application/json', 'content-length': '546', 'connection': 'keep-alive', 'x-amzn-requestid': '73045f3e-d24a-4375-b2ed-652107cccf75'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [3263]}, 'model_name': 'us.anthropic.claude-3-5-haiku-20241022-v1:0'}, id='run--c565b235-15b6-440d-89b4-d76b77210ab1-0', usage_metadata={'input_tokens': 497, 'output_tokens': 111, 'total_tokens': 608, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"どちらの方が暖かいですか?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c607bb30",
   "metadata": {},
   "source": [
    "## トークンレベルのストリーミング\n",
    "\n",
    "ストリーミングへのより細かいアプローチとして、`astream_events`メソッドを使用してトークンレベルの更新を実装します。この非同期メソッドは非同期チェックポインターを必要とし、`AsyncSqliteSaver`を使用して実装します。\n",
    "\n",
    "非同期プログラミングにより、アプリケーションはメイン実行スレッドをブロックすることなく、複数の操作を同時に処理できます。AIモデルからのトークンのストリーミングのコンテキストでは、これはトークンが生成されるにつれて処理して表示することを意味し、より応答性の高いユーザーエクスペリエンスをもたらします。`astream_events`メソッドはこの非同期アプローチを活用して、Claudeからトークンレベルの更新を効率的にストリーミングします。\n",
    "\n",
    "新しいスレッドIDで新しい会話を開始し、イベントを反復処理して、特に「on_chat_model_stream」タイプのイベントを探します。これらのイベントに遭遇すると、コンテンツを抽出して表示します。\n",
    "\n",
    "実行すると、リアルタイムでトークンがストリーミングされるのを観察できます。Claudeが関数を呼び出す（ストリーミング可能なコンテンツを生成しない）のを見た後、最終的な応答がトークンごとにストリーミングされるのを見ることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'tool_use', 'name': 'tavily_search_results_json', 'id': 'tooluse_lW7zo05zRXy65kFqL949tw', 'index': 0}]|[{'type': 'tool_use', 'input': '', 'id': None, 'index': 0}]|[{'type': 'tool_use', 'input': '{\"query', 'id': None, 'index': 0}]|[{'type': 'tool_use', 'input': '\": \"サンフ', 'id': None, 'index': 0}]|[{'type': 'tool_use', 'input': 'ランシスコ 現在', 'id': None, 'index': 0}]|[{'type': 'tool_use', 'input': 'の天気', 'id': None, 'index': 0}]|[{'type': 'tool_use', 'input': '\"}', 'id': None, 'index': 0}]|[{'index': 0}]|Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'サンフランシスコ 現在の天気'}, 'id': 'tooluse_lW7zo05zRXy65kFqL949tw', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "[{'type': 'text', 'text': '\\n\\n現', 'index': 0}]|[{'type': 'text', 'text': '在の', 'index': 0}]|[{'type': 'text', 'text': 'サンフランシ', 'index': 0}]|[{'type': 'text', 'text': 'スコの天', 'index': 0}]|[{'type': 'text', 'text': '気は以', 'index': 0}]|[{'type': 'text', 'text': '下のようです', 'index': 0}]|[{'type': 'text', 'text': '：\\n\\n- 気', 'index': 0}]|[{'type': 'text', 'text': '温：約', 'index': 0}]|[{'type': 'text', 'text': '18', 'index': 0}]|[{'type': 'text', 'text': '℃（64', 'index': 0}]|[{'type': 'text', 'text': '-65°F）', 'index': 0}]|[{'type': 'text', 'text': '\\n- 天候', 'index': 0}]|[{'type': 'text', 'text': '：おおむね', 'index': 0}]|[{'type': 'text', 'text': '曇り\\n- 風：', 'index': 0}]|[{'type': 'text', 'text': '西南西の', 'index': 0}]|[{'type': 'text', 'text': '方向', 'index': 0}]|[{'type': 'text', 'text': 'に約5-7 mph', 'index': 0}]|[{'type': 'text', 'text': '（時速8', 'index': 0}]|[{'type': 'text', 'text': '-11キロ）', 'index': 0}]|[{'type': 'text', 'text': '\\n- 降水確', 'index': 0}]|[{'type': 'text', 'text': '率：0%', 'index': 0}]|[{'type': 'text', 'text': '\\n\\n午後は', 'index': 0}]|[{'type': 'text', 'text': '気温が少', 'index': 0}]|[{'type': 'text', 'text': 'し下がり', 'index': 0}]|[{'type': 'text', 'text': '、16-17', 'index': 0}]|[{'type': 'text', 'text': '℃くらいになる', 'index': 0}]|[{'type': 'text', 'text': '予報', 'index': 0}]|[{'type': 'text', 'text': 'です。夜は', 'index': 0}]|[{'type': 'text', 'text': '13-14℃', 'index': 0}]|[{'type': 'text', 'text': 'まで下がる', 'index': 0}]|[{'type': 'text', 'text': '見込みです', 'index': 0}]|[{'type': 'text', 'text': '。全', 'index': 0}]|[{'type': 'text', 'text': '体的に', 'index': 0}]|[{'type': 'text', 'text': '曇りが', 'index': 0}]|[{'type': 'text', 'text': 'ちで', 'index': 0}]|[{'type': 'text', 'text': '、', 'index': 0}]|[{'type': 'text', 'text': '雨の可能性は低', 'index': 0}]|[{'type': 'text', 'text': 'いようです。\\n\\n何', 'index': 0}]|[{'type': 'text', 'text': 'か他', 'index': 0}]|[{'type': 'text', 'text': 'に知りたい', 'index': 0}]|[{'type': 'text', 'text': 'ことはありますか？', 'index': 0}]|[{'index': 0}]|"
     ]
    }
   ],
   "source": [
    "# # 新しいバージョンのLangGraphを使用している場合、パッケージは分離されています：\n",
    "# # !pip install langgraph-checkpoint-sqlite\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\n",
    "\n",
    "# 非同期SQLiteセーバーを使用してチェックポイントデータベースに接続\n",
    "async with AsyncSqliteSaver.from_conn_string(\"checkpoints.db\") as memory:\n",
    "    # メモリチェックポインターを使用してエージェントを初期化\n",
    "    abot = Agent(model, [tool], system=prompt, checkpointer=memory)\n",
    "    \n",
    "    # 「サンフランシスコの天気は？」という質問を含むメッセージを作成\n",
    "    messages = [HumanMessage(content=\"サンフランシスコの天気は？\")]\n",
    "    \n",
    "    # スレッドIDを設定（会話の永続性を管理するため）\n",
    "    thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "    \n",
    "    # イベントストリームを非同期で処理\n",
    "    async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "        # イベントの種類を取得\n",
    "        kind = event[\"event\"]\n",
    "        \n",
    "        # チャットモデルのストリーミングイベントを処理\n",
    "        if kind == \"on_chat_model_stream\":\n",
    "            # チャンクからコンテンツを抽出\n",
    "            content = event[\"data\"][\"chunk\"].content\n",
    "            \n",
    "            if content:\n",
    "                # 空でないコンテンツのみを表示\n",
    "                # Amazon Bedrockのコンテキストでは、空のコンテンツはモデルがツールの呼び出しを要求していることを意味します\n",
    "                # そのため、空でないコンテンツのみを表示します\n",
    "                print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e0e9e",
   "metadata": {},
   "source": [
    "## 結論\n",
    "\n",
    "この実習では、Amazon Bedrock上のAnthropic Claudeモデルを使用した永続性とストリーミングの実装について包括的に探求しました。これらの概念は実装が簡単ですが、本番環境グレードのAIアプリケーションを構築するための強力な機能を提供します。\n",
    "\n",
    "複数の同時会話を管理する能力と、会話再開のための堅牢なメモリシステムは、スケーラブルなAIソリューションにとって重要です。さらに、最終トークンと中間メッセージの両方をストリーミングする能力は、AIの意思決定プロセスに対する比類のない可視性を提供します。\n",
    "\n",
    "永続性はまた、人間を介在させる相互作用を可能にする上で重要な役割を果たしており、これは次の実習でより深く探求するトピックです。\n",
    "\n",
    "これらの概念の実践的な意味をより深く理解するために、本番環境のAIアプリケーションにおける永続性とストリーミングの実際のケーススタディを探索することをお勧めします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df424a98",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
