# ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆå¯¾å¿œ dbt Analytics å®Œå…¨ã‚¬ã‚¤ãƒ‰

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒï¼ˆDockerï¼‰ã§ã®å®Ÿè¡Œ

```bash
# Dockerç’°å¢ƒèµ·å‹•
docker compose up -d

# Step 1: dbtç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
# å®Ÿæ…‹ã®ã‚³ãƒãƒ³ãƒ‰: docker exec multitenant-analytics-platform-dbt-local-1 dbt debug
# ä½•ã‚’ã‚„ã£ã¦ã„ã‚‹: dbt ã®ç’°å¢ƒãƒã‚§ãƒƒã‚¯
./4-etl-manager.sh -p aurora-postgresql -c config.json --local --step1

# Step 2: dbtãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œ
## å®Ÿæ…‹ã®ã‚³ãƒãƒ³ãƒ‰: docker exec multitenant-analytics-platform-dbt-local-1 dbt run
## ä½•ã‚’ã‚„ã£ã¦ã„ã‚‹: ãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ãƒ“ãƒ¥ãƒ¼ã‚’ä½œæˆã™ã‚‹
./4-etl-manager.sh -p aurora-postgresql -c config.json --local --step2

## æ¤œè¨¼ã‚³ãƒãƒ³ãƒ‰
./4-etl-manager.sh -p aurora-postgresql -c config.json --local --bastion-command "echo '=== STEP 2 VERIFICATION ===' && echo '1. Models created:' && dbt ls && echo '2. Seed data:' && dbt seed && echo '3. Models execution:' && dbt run && echo '4. Data check:' && dbt show --select tenant_a_users --limit 3 && echo '5. All users (should show data if macros work):' && dbt show --select all_users --limit 5"

# Step 3: dbtãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
## å®Ÿæ…‹ã®ã‚³ãƒãƒ³ãƒ‰: docker exec multitenant-analytics-platform-dbt-local-1 dbt test
## ä½•ã‚’ã‚„ã£ã¦ã„ã‚‹: ãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ãƒ“ãƒ¥ãƒ¼ã«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥ã™ã‚‹
./4-etl-manager.sh -p aurora-postgresql -c config.json --local --step3

## æ­£å¸¸ã«ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ»ãƒ“ãƒ¥ãƒ¼ã«ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒæŠ•å…¥ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
## ãƒ¢ãƒ‡ãƒ«åã‚’æŒ‡å®šã—ã¦ä½œæˆã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ã®ä¸­èº«ã‚’ç¢ºèªã§ãã‚‹

# ã‚«ã‚¹ã‚¿ãƒ dbtã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
./4-etl-manager.sh -p aurora-postgresql -c config.json --local --bastion-command "dbt run --select all_users"
```

### AWSç’°å¢ƒï¼ˆBastion HostçµŒç”±ï¼‰ã§ã®å®Ÿè¡Œ

```bash
# Step 1: dbtç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
./4-etl-manager.sh -p aurora-postgresql -c config.json --step1

# Step 2: dbtãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œ
./4-etl-manager.sh -p aurora-postgresql -c config.json --step2

# Step 3: dbtãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
./4-etl-manager.sh -p aurora-postgresql -c config.json --step3

# çµæœç¢ºèªï¼ˆçµ±ä¸€èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ï¼‰
./4-etl-manager.sh -p aurora-postgresql -c config.json --bastion-command "scripts/4-sql-execute.sh config.json sql/redshift/verification/verify-zero-etl-all-users.sql"
```

## ğŸ“‹ å®Ÿè¡Œæ–¹æ³•

### ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®å‹•ä½œç¢ºèª

#### å‰ææ¡ä»¶
- Docker ãŠã‚ˆã³ Docker ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿

#### ã‚¹ãƒ†ãƒƒãƒ—1: Dockerç’°å¢ƒã®èµ·å‹•

```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã§å®Ÿè¡Œ
docker compose up -d

# å®Ÿè¡Œçµæœã®ç¢ºèª
docker compose ps
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:**
```
NAME                                         SERVICE     STATUS
multitenant-analytics-platform-postgres-1   postgres    Up
multitenant-analytics-platform-dbt-local-1  dbt-local   Up
```

#### ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ†ãƒŠãƒ³ãƒˆã‚¹ã‚­ãƒ¼ãƒã®ç¢ºèª

```bash
# PostgreSQLã«æ¥ç¶šã—ã¦ã‚¹ã‚­ãƒ¼ãƒä¸€è¦§ã‚’ç¢ºèª
docker compose exec postgres psql -U dbt_user -d multitenant_analytics -c "\dn"
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:**
```
   Name   |       Owner
----------+-------------------
 public   | pg_database_owner
 tenant_a | dbt_user
 tenant_b | dbt_user
 tenant_c | dbt_user
(4 rows)
```

#### ã‚¹ãƒ†ãƒƒãƒ—3: dbtãƒã‚¯ãƒ­ã®æ§‹æ–‡ãƒã‚§ãƒƒã‚¯

```bash
# dbtãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹æ–‡ãƒã‚§ãƒƒã‚¯
docker compose exec dbt-local dbt parse
```

#### ã‚¹ãƒ†ãƒƒãƒ—4: dbtå®Ÿè¡Œï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰

```bash
# Step 1: dbtç’°å¢ƒç¢ºèª
./4-etl-manager.sh -p aurora-posgtgresql -c config.json --local --step1

# Step 2: dbtãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œ
./4-etl-manager.sh -p aurora-postgresql -c config.json --local --step2

# Step 3: dbtãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
./4-etl-manager.sh -p aurora-postgresql -c config.json --local --step3
```

#### ã‚¹ãƒ†ãƒƒãƒ—5: çµæœç¢ºèª

```bash
# ä½œæˆã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèª
docker compose exec postgres psql -U dbt_user -d multitenant_analytics -c "
SELECT tenant_id, count(*) as user_count 
FROM all_users 
GROUP BY tenant_id 
ORDER BY tenant_id;
"
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:**
```
 tenant_id | user_count
-----------+------------
 tenant_a  |          2
 tenant_b  |          2
 tenant_c  |          2
(3 rows)
```

### AWSç’°å¢ƒï¼ˆBastion HostçµŒç”±ï¼‰ã§ã®å®Ÿè¡Œ

#### å‰ææ¡ä»¶
- Phase 1, 2, 3ã®å®Œäº†
- `bastion-redshift-connection.json` (Phase 3ã§ç”Ÿæˆ)
- `config.json` (ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š)
- IAMæ¨©é™ï¼ˆAdministratorAccessãŒã‚¢ã‚¿ãƒƒãƒã•ã‚Œã¦ã„ã‚Œã°ååˆ†ï¼‰

#### ã‚¹ãƒ†ãƒƒãƒ—1: dbtç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
./4-etl-manager.sh -p aurora-postgresql -c config.json --step1
```

**å®Ÿè¡Œå†…å®¹:**
- Bastion Hostã«dbt-redshift 1.5.0ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
- å¿…è¦ãªä¾å­˜é–¢ä¿‚ï¼ˆgit, redshift-connectorç­‰ï¼‰ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- dbtç’°å¢ƒã®å‹•ä½œç¢ºèª

#### ã‚¹ãƒ†ãƒƒãƒ—2: dbtãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œ

```bash
./4-etl-manager.sh -p aurora-postgresql -c config.json --step2
```

**å®Ÿè¡Œå†…å®¹:**
- Zero-ETLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ†ãƒŠãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
- `analytics_analytics.zero_etl_all_users` ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ
- ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ

#### ã‚¹ãƒ†ãƒƒãƒ—3: dbtãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

```bash
./4-etl-manager.sh -p aurora-postgresql -c config.json --step3
```

**å®Ÿè¡Œå†…å®¹:**
- ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
- ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ•´åˆæ€§ã‚’ç¢ºèª
- ãƒ†ã‚¹ãƒˆçµæœã‚’ãƒ¬ãƒãƒ¼ãƒˆ

#### ã‚¹ãƒ†ãƒƒãƒ—4: çµæœç¢ºèª

```bash
# çµ±ä¸€èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ã§ã®çµæœç¢ºèª
./4-etl-manager.sh -p aurora-postgresql -c config.json --bastion-command "scripts/4-sql-execute.sh config.json sql/redshift/verification/verify-zero-etl-all-users.sql"

# é«˜é€Ÿå®Ÿè¡Œï¼ˆãƒ•ã‚¡ã‚¤ãƒ«è»¢é€ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
./4-etl-manager.sh -p aurora-postgresql -c config.json --skip-copy --bastion-command "scripts/4-sql-execute.sh config.json sql/redshift/verification/verify-zero-etl-all-users.sql"
```

### ã‚«ã‚¹ã‚¿ãƒ dbtã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ

#### ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ

```bash
# ç‰¹å®šã®ãƒ¢ãƒ‡ãƒ«ã®ã¿å®Ÿè¡Œ
./4-etl-manager.sh -p aurora-postgresql -c config.json --local --bastion-command "dbt run --select all_users"

# dbtãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
./4-etl-manager.sh -p aurora-postgresql -c config.json --local --bastion-command "dbt docs generate"

# dbtã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã®ã¿
./4-etl-manager.sh -p aurora-postgresql -c config.json --local --bastion-command "dbt compile --select all_users"
```

#### AWSç’°å¢ƒ

```bash
# ç‰¹å®šã®ãƒ¢ãƒ‡ãƒ«ã®ã¿å®Ÿè¡Œ
./4-etl-manager.sh -p aurora-postgresql -c config.json --bastion-command "scripts/4-dbt-execute.sh config.json 'dbt run --select all_users'"

# dbtãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
./4-etl-manager.sh -p aurora-postgresql -c config.json --bastion-command "scripts/4-dbt-execute.sh config.json 'dbt docs generate'"
```

---

## ğŸ“š å‰ææ¡ä»¶

### Phase 1, 2, 3ã®å®Œäº†

```bash
# Phase 1: Aurora infrastructure
./1-etl-manager.sh -p aurora-postgresql -c config.json

# Phase 2: Data population
./2-etl-manager.sh -p aurora-postgresql -c config.json

# Phase 3: Zero-ETL integration
./3-etl-manager.sh -p aurora-postgresql -c config.json --step1 --step2 --step3
```

### å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«

- `bastion-redshift-connection.json` (Phase 3ã§ç”Ÿæˆ)
- `config.json` (ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š)

### ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®è¦ä»¶

- Docker 20.10ä»¥ä¸Š
- Docker Compose 2.0ä»¥ä¸Š
- 8GBä»¥ä¸Šã®ãƒ¡ãƒ¢ãƒªæ¨å¥¨

### AWSç’°å¢ƒã®è¦ä»¶

- AWS CLIè¨­å®šæ¸ˆã¿
- IAMæ¨©é™ï¼ˆAdministratorAccessã¾ãŸã¯åŒç­‰ã®æ¨©é™ï¼‰
- Zero-ETLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ `multitenant_analytics_zeroetl` ã®å­˜åœ¨

---

## ğŸ—ï¸ å®Ÿè£…ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### å…¨ä½“åƒ

```mermaid
graph TB
    subgraph "ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹"
        A1[Aurora PostgreSQL<br/>tenant_a.users]
        A2[Aurora PostgreSQL<br/>tenant_b.users]
        A3[Aurora PostgreSQL<br/>tenant_c.users]
        A4[Aurora PostgreSQL<br/>tenant_...<br/>1000+ tenants]
    end
    
    subgraph "Zero-ETL Integration"
        B[Amazon Redshift<br/>multitenant_analytics_zeroetl]
    end
    
    subgraph "dbt Transformation Layer"
        C1[get_zero_etl_tenant_schemas<br/>ãƒ†ãƒŠãƒ³ãƒˆè‡ªå‹•æ¤œå‡º]
        C2[union_zero_etl_tenant_tables_optimized<br/>å‹•çš„UNIONç”Ÿæˆ]
        C3[ãƒãƒƒãƒå‡¦ç†<br/>100ãƒ†ãƒŠãƒ³ãƒˆ/ãƒãƒƒãƒ]
    end
    
    subgraph "åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿"
        D[Redshift Analytics<br/>all_users ãƒ†ãƒ¼ãƒ–ãƒ«]
    end
    
    A1 --> B
    A2 --> B
    A3 --> B
    A4 --> B
    
    B --> C1
    C1 --> C2
    C2 --> C3
    C3 --> D
    
    style C1 fill:#e1f5ff
    style C2 fill:#e1f5ff
    style C3 fill:#e1f5ff
```

### ä½œæˆã•ã‚Œã‚‹ãƒªã‚½ãƒ¼ã‚¹

#### ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ
1. **PostgreSQL 15**: ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
2. **dbt-local container**: dbtå®Ÿè¡Œç’°å¢ƒ
3. **all_users table**: å…¨ãƒ†ãƒŠãƒ³ãƒˆçµ±åˆãƒ†ãƒ¼ãƒ–ãƒ«

#### AWSç’°å¢ƒ
1. **dbt-redshift 1.5.0**: å®Œå…¨ãªdbtãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ç’°å¢ƒ
2. **`analytics_analytics` schema**: dbtç®¡ç†ä¸‹ã®åˆ†æç”¨ã‚¹ã‚­ãƒ¼ãƒ
3. **`analytics_analytics.zero_etl_all_users`**: å…¨ãƒ†ãƒŠãƒ³ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼çµ±åˆTable
4. **dbtãƒ†ã‚¹ãƒˆ**: ãƒ‡ãƒ¼ã‚¿å“è³ªä¿è¨¼ã®è‡ªå‹•ãƒ†ã‚¹ãƒˆ

---

## ğŸ“š dbt Jinja ã¨ Macros ã®åŸºç¤

### dbt ã¨ã¯ï¼Ÿ

**dbt (data build tool)** ã¯ã€SQLãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ„ãƒ¼ãƒ«ã§ã€ä»¥ä¸‹ã®ç‰¹å¾´ãŒã‚ã‚Šã¾ã™ï¼š

- ğŸ“ SQLã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸå®£è¨€çš„ãªãƒ‡ãƒ¼ã‚¿å¤‰æ›
- ğŸ”„ ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨ãƒ†ã‚¹ãƒˆã®çµ±åˆ
- ğŸ¨ Jinjaãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ã‚ˆã‚‹å‹•çš„SQLç”Ÿæˆ
- ğŸ§© å†åˆ©ç”¨å¯èƒ½ãªãƒã‚¯ãƒ­æ©Ÿèƒ½

### Jinja ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¨ãƒ³ã‚¸ãƒ³ã¨ã¯ï¼Ÿ

**Jinja** ã¯ã€Pythonã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¨ãƒ³ã‚¸ãƒ³ã§ã€ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š

```mermaid
graph LR
    A[Jinjaãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ] --> B[å¤‰æ•°å±•é–‹]
    A --> C[æ¡ä»¶åˆ†å²]
    A --> D[ãƒ«ãƒ¼ãƒ—å‡¦ç†]
    A --> E[é–¢æ•°å‘¼ã³å‡ºã—]
    
    B --> F[å‹•çš„SQLç”Ÿæˆ]
    C --> F
    D --> F
    E --> F
```

### Jinja ã®åŸºæœ¬è¨˜æ³•

#### 1. ã‚³ãƒ¡ãƒ³ãƒˆ

```jinja
{# ã“ã‚Œã¯ã‚³ãƒ¡ãƒ³ãƒˆã§ã™ã€‚å‡ºåŠ›ã•ã‚Œã¾ã›ã‚“ #}
```

#### 2. å¤‰æ•°ã®å±•é–‹

```jinja
{# å¤‰æ•°ã‚’å±•é–‹ #}
{{ variable_name }}

{# ä¾‹ï¼šãƒ†ãƒŠãƒ³ãƒˆåã‚’å±•é–‹ #}
SELECT * FROM {{ tenant_schema }}.users
-- çµæœ: SELECT * FROM tenant_a.users
```

#### 3. åˆ¶å¾¡æ§‹æ–‡ - æ¡ä»¶åˆ†å²

```jinja
{% if target.type == 'redshift' %}
  -- Redshiftç”¨ã®SQL
  SELECT * FROM database.schema.table
{% elif target.type == 'postgres' %}
  -- PostgreSQLç”¨ã®SQL
  SELECT * FROM schema.table
{% else %}
  -- ãã®ä»–ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
  SELECT * FROM table
{% endif %}
```

#### 4. åˆ¶å¾¡æ§‹æ–‡ - ãƒ«ãƒ¼ãƒ—

```jinja
{% for tenant in tenant_list %}
  SELECT * FROM {{ tenant }}.users
  {% if not loop.last %}
  UNION ALL
  {% endif %}
{% endfor %}
```

**ãƒ«ãƒ¼ãƒ—å¤‰æ•°:**
- `loop.index0`: 0ã‹ã‚‰å§‹ã¾ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
- `loop.index`: 1ã‹ã‚‰å§‹ã¾ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
- `loop.first`: æœ€åˆã®è¦ç´ ã‹ã©ã†ã‹ï¼ˆbooleanï¼‰
- `loop.last`: æœ€å¾Œã®è¦ç´ ã‹ã©ã†ã‹ï¼ˆbooleanï¼‰

#### 5. å¤‰æ•°ã®è¨­å®š

```jinja
{# å˜ä¸€å¤‰æ•° #}
{% set my_variable = 'value' %}

{# ãƒªã‚¹ãƒˆ #}
{% set tenant_list = ['tenant_a', 'tenant_b', 'tenant_c'] %}

{# è¾æ›¸ #}
{% set config = {'batch_size': 100, 'timeout': 3600} %}
```

### Macrosï¼ˆãƒã‚¯ãƒ­ï¼‰ã¨ã¯ï¼Ÿ

**Macros** ã¯ã€å†åˆ©ç”¨å¯èƒ½ãªSQLé–¢æ•°ã®ã‚ˆã†ãªã‚‚ã®ã§ã€è¤‡é›‘ãªãƒ­ã‚¸ãƒƒã‚¯ã‚’ã‚«ãƒ—ã‚»ãƒ«åŒ–ã—ã¾ã™ã€‚

#### ãƒã‚¯ãƒ­ã®åŸºæœ¬æ§‹é€ 

```jinja
{% macro macro_name(parameter1, parameter2='default_value') %}
  {# ãƒã‚¯ãƒ­ã®å‡¦ç†å†…å®¹ #}
  SELECT {{ parameter1 }} FROM {{ parameter2 }}
{% endmacro %}
```

#### ãƒã‚¯ãƒ­ã®å‘¼ã³å‡ºã—

```jinja
{# åŸºæœ¬çš„ãªå‘¼ã³å‡ºã— #}
{{ macro_name('column_name', 'table_name') }}

{# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ #}
{{ macro_name('column_name') }}
```

### é‡è¦ãªdbté–¢æ•°

#### 1. `run_query()` - SQLã‚¯ã‚¨ãƒªã®å®Ÿè¡Œ

```jinja
{% set query %}
  SELECT schema_name 
  FROM information_schema.schemata 
  WHERE schema_name LIKE 'tenant_%'
{% endset %}

{% if execute %}
  {% set results = run_query(query) %}
  {% set tenant_schemas = results.columns[0].values() %}
{% endif %}
```

#### 2. `log()` - ãƒ­ã‚°å‡ºåŠ›

```jinja
{{ log("Processing " ~ tenant_count ~ " tenants", info=true) }}
```

#### 3. `var()` - è¨­å®šå€¤ã®å–å¾—

```jinja
{# dbt_project.ymlã‹ã‚‰å€¤ã‚’å–å¾— #}
{% set batch_size = var('tenant_processing', {}).get('batch_size', 50) %}
```

#### 4. `config()` - ãƒ¢ãƒ‡ãƒ«è¨­å®š

```sql
{{ config(
    materialized='table',
    schema='analytics',
    tags=['daily']
) }}
```

---

## ğŸ—ï¸ å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³è©³ç´°è§£èª¬

### ãƒ‘ã‚¿ãƒ¼ãƒ³1: ãƒ†ãƒŠãƒ³ãƒˆã‚¹ã‚­ãƒ¼ãƒã®å‹•çš„æ¤œå‡º

#### å‡¦ç†ãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant M as Macroå‘¼ã³å‡ºã—
    participant D as ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
    participant R as çµæœ
    
    M->>M: get_zero_etl_tenant_schemas()å®Ÿè¡Œ
    M->>D: information_schemaã‚¯ã‚¨ãƒª
    Note over D: SELECT schemaname<br/>WHERE schemaname LIKE 'tenant_%'
    D->>M: ã‚¹ã‚­ãƒ¼ãƒä¸€è¦§ã‚’è¿”å´
    M->>M: ãƒªã‚¹ãƒˆã«å¤‰æ›
    M->>R: ['tenant_a', 'tenant_b', ...]
```

#### ãƒã‚¯ãƒ­å®Ÿè£…: `get_zero_etl_tenant_schemas()`

```jinja
{% macro get_zero_etl_tenant_schemas(zeroetl_database=none) %}
  {# 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åã®å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚ã‚Šï¼‰ #}
  {% if zeroetl_database is none %}
    {% set zeroetl_database = var('zeroetl_database', 'multitenant_analytics_zeroetl') %}
  {% endif %}
  
  {# 2. ãƒ†ãƒŠãƒ³ãƒˆã‚¹ã‚­ãƒ¼ãƒæ¤œå‡ºSQLã‚’å®šç¾© #}
  {% if target.type == 'redshift' %}
    {# Redshiftç”¨ã®ã‚¯ãƒ­ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒª #}
    {% set tenant_query %}
      select distinct schemaname as schema_name
      from {{ zeroetl_database }}.information_schema.schemata
      where lower(schemaname) like 'tenant_%'
      order by schemaname
    {% endset %}
  {% else %}
    {# PostgreSQLç­‰ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ #}
    {% set tenant_query %}
      select distinct schema_name 
      from information_schema.schemata 
      where lower(schema_name) like 'tenant_%'
      order by schema_name
    {% endset %}
  {% endif %}
  
  {# 3. ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¦ãƒ†ãƒŠãƒ³ãƒˆä¸€è¦§ã‚’å–å¾— #}
  {% if execute %}
    {% set results = run_query(tenant_query) %}
    {% if results and results.rows|length > 0 %}
      {% set tenant_schemas = results.columns[0].values() %}
      {{ log("Found " ~ tenant_schemas|length ~ " tenant schemas", info=true) }}
      {{ return(tenant_schemas) }}
    {% else %}
      {# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ #}
      {{ return(['tenant_a', 'tenant_b', 'tenant_c']) }}
    {% endif %}
  {% else %}
    {# ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ #}
    {{ return(['tenant_a', 'tenant_b', 'tenant_c']) }}
  {% endif %}
{% endmacro %}
```

### ãƒ‘ã‚¿ãƒ¼ãƒ³2: ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹å¤§é‡ãƒ†ãƒŠãƒ³ãƒˆå¯¾å¿œ

#### ãªãœãƒãƒƒãƒå‡¦ç†ãŒå¿…è¦ï¼Ÿ

```mermaid
graph TB
    subgraph "âŒ ãƒãƒƒãƒå‡¦ç†ãªã—ï¼ˆ1000ãƒ†ãƒŠãƒ³ãƒˆï¼‰"
        A1[1000å€‹ã®UNION ALL] --> B1[å·¨å¤§ãªSQL<br/>10,000è¡Œä»¥ä¸Š]
        B1 --> C1[ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³æœ€é©åŒ–å›°é›£]
        C1 --> D1[ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼]
    end
    
    subgraph "âœ… ãƒãƒƒãƒå‡¦ç†ã‚ã‚Šï¼ˆ1000ãƒ†ãƒŠãƒ³ãƒˆï¼‰"
        A2[10ãƒãƒƒãƒ Ã— 100ãƒ†ãƒŠãƒ³ãƒˆ] --> B2[CTEåˆ†å‰²<br/>ç®¡ç†å¯èƒ½ãªã‚µã‚¤ã‚º]
        B2 --> C2[ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³æœ€é©åŒ–]
        C2 --> D2[å®‰å®šã—ãŸå®Ÿè¡Œ]
    end
    
    style D1 fill:#ffcccc
    style D2 fill:#ccffcc
```

#### ãƒãƒƒãƒå‡¦ç†ã®ä»•çµ„ã¿

```mermaid
graph LR
    A[1000ãƒ†ãƒŠãƒ³ãƒˆ] --> B[ãƒãƒƒãƒåˆ†å‰²<br/>batch_size=100]
    B --> C1[batch_0<br/>tenant_001-100]
    B --> C2[batch_1<br/>tenant_101-200]
    B --> C3[batch_2<br/>tenant_201-300]
    B --> C4[...]
    B --> C5[batch_9<br/>tenant_901-1000]
    
    C1 --> D[CTEçµåˆ]
    C2 --> D
    C3 --> D
    C4 --> D
    C5 --> D
    
    D --> E[æœ€çµ‚çµæœ]
```

### ãƒ‘ã‚¿ãƒ¼ãƒ³3: å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ã§ã®ä½¿ç”¨

#### ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: `zero_etl_all_users.sql`

```sql
-- å‹•çš„Zero-ETLå…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¢ãƒ‡ãƒ« - 1000+ãƒ†ãƒŠãƒ³ãƒˆå¯¾å¿œ
{{ config(materialized='table', schema='analytics') }}

-- ãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ç¢ºèªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
{%- set missing_tables = validate_tenant_table_exists('users') -%}

-- å‹•çš„ã«å…¨ãƒ†ãƒŠãƒ³ãƒˆã®usersãƒ†ãƒ¼ãƒ–ãƒ«ã‚’UNION
WITH tenant_users AS (
{{ union_zero_etl_tenant_tables_optimized('users', 
   'user_id,
    email,
    first_name,
    last_name,
    registration_date,
    last_login_date,
    account_status,
    subscription_tier,
    created_at,
    updated_at',
   batch_size=100
) }}
)

-- ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¨æœ€çµ‚é¸æŠ
SELECT 
    tenant_id,
    user_id,
    lower(trim(email)) as email,
    trim(first_name) as first_name,
    trim(last_name) as last_name,
    registration_date,
    last_login_date,
    upper(trim(account_status)) as account_status,
    lower(trim(subscription_tier)) as subscription_tier,
    created_at,
    updated_at,
    current_timestamp as dbt_loaded_at
FROM tenant_users
WHERE user_id IS NOT NULL
  AND email IS NOT NULL
ORDER BY tenant_id, user_id
```

---

## ğŸ“ ä½œæˆãƒ»æ›´æ–°ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«

### ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```mermaid
graph TB
    subgraph "Macrosï¼ˆå†åˆ©ç”¨å¯èƒ½ãªãƒ­ã‚¸ãƒƒã‚¯ï¼‰"
        M1[zero_etl_tenant_macros.sql<br/>Zero-ETLå°‚ç”¨ãƒã‚¯ãƒ­]
        M2[get_tenant_table_ref.sql<br/>ãƒ†ãƒ¼ãƒ–ãƒ«å‚ç…§ç”Ÿæˆ]
        M3[advanced_tenant_processing.sql<br/>é«˜åº¦ãªå‡¦ç†æ©Ÿèƒ½]
        M4[performance_benchmark.sql<br/>ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–]
    end
    
    subgraph "Modelsï¼ˆãƒ‡ãƒ¼ã‚¿å¤‰æ›ï¼‰"
        D1[zero_etl_all_users.sql<br/>Zero-ETLå…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼]
        D2[all_users.sql<br/>é€šå¸¸ç‰ˆå…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼]
    end
    
    subgraph "Testsï¼ˆå“è³ªä¿è¨¼ï¼‰"
        T1[test_large_scale_tenant_processing.sql<br/>å¤§è¦æ¨¡ãƒ†ã‚¹ãƒˆ]
    end
    
    subgraph "Configurationï¼ˆè¨­å®šï¼‰"
        C1[dbt_project.yml<br/>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š]
    end
    
    M1 --> D1
    M2 --> D2
    M3 --> D1
    M3 --> D2
    M4 --> T1
    C1 --> M1
    C1 --> M2
    C1 --> M3
```

### ä¸»è¦ãƒã‚¯ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«

#### `dbt/macros/zero_etl_tenant_macros.sql`

**Zero-ETLå°‚ç”¨ãƒã‚¯ãƒ­ç¾¤**

| ãƒã‚¯ãƒ­å | æ©Ÿèƒ½ |
|---------|------|
| `get_zero_etl_tenant_schemas()` | Zero-ETLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ†ãƒŠãƒ³ãƒˆã‚¹ã‚­ãƒ¼ãƒã‚’å‹•çš„æ¤œå‡º |
| `union_zero_etl_tenant_tables()` | ãƒãƒƒãƒå‡¦ç†å¯¾å¿œã®UNIONãƒã‚¯ãƒ­ |
| `validate_tenant_table_exists()` | ãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ç¢ºèª |
| `get_tenant_table_columns()` | ã‚«ãƒ©ãƒ æƒ…å ±å‹•çš„å–å¾— |

#### `dbt/macros/advanced_tenant_processing.sql`

**é«˜åº¦ãªå‡¦ç†æ©Ÿèƒ½**

| ãƒã‚¯ãƒ­å | æ©Ÿèƒ½ |
|---------|------|
| `get_filtered_tenant_schemas()` | è¨­å®šãƒ™ãƒ¼ã‚¹ã®ãƒ†ãƒŠãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° |
| `union_tenant_tables_optimized()` | æœ€é©åŒ–ã•ã‚ŒãŸUNIONå‡¦ç† |
| `log_tenant_processing_stats()` | å‡¦ç†çµ±è¨ˆãƒ­ã‚°å‡ºåŠ› |
| `create_incremental_tenant_model()` | ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«å‡¦ç†ã‚µãƒãƒ¼ãƒˆ |

---

## âš™ï¸ è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³

### `dbt_project.yml` ã®ä¸»è¦è¨­å®š

```yaml
vars:
  # Zero-ETLè¨­å®š
  zeroetl_database: "multitenant_analytics_zeroetl"
  
  # å¤§é‡ãƒ†ãƒŠãƒ³ãƒˆå‡¦ç†è¨­å®š
  tenant_processing:
    batch_size: 50                    # SQLãƒãƒƒãƒã‚µã‚¤ã‚º
    parallel_group_size: 100          # ä¸¦åˆ—å‡¦ç†ã‚µã‚¤ã‚º
    max_tenant_limit: 2000           # å®‰å…¨è£…ç½®
    enable_tenant_filter: false       # é–‹ç™ºæ™‚ãƒ•ã‚£ãƒ«ã‚¿
    filtered_tenants: []              # ãƒ•ã‚£ãƒ«ã‚¿å¯¾è±¡
  
  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
  performance:
    enable_incremental: true          # ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«å‡¦ç†
    query_timeout_seconds: 3600       # ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    enable_memory_optimization: true  # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
  
  # ãƒ­ã‚°ã¨ç›£è¦–
  logging:
    enable_verbose_logging: true      # è©³ç´°ãƒ­ã‚°
    show_tenant_progress: true        # é€²æ—è¡¨ç¤º
    show_performance_stats: true      # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
```

### é–‹ç™ºæ™‚ã®ãƒ†ãƒŠãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

```yaml
# dbt_project.yml ã§è¨­å®š
vars:
  tenant_processing:
    enable_tenant_filter: true
    filtered_tenants: 
      - "tenant_001"
      - "tenant_002" 
      - "tenant_003"
```

```bash
# ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é©ç”¨
./4-etl-manager.sh -p aurora-postgresql -c config.json --local --step2
```

---

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™

### ãƒãƒƒãƒã‚µã‚¤ã‚ºåˆ¥æ¨å¥¨äº‹é …

| ãƒ†ãƒŠãƒ³ãƒˆæ•° | æ¨å¥¨ãƒãƒƒãƒã‚µã‚¤ã‚º | ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡(æ¨å®š) | å‡¦ç†æ™‚é–“(æ¨å®š) | ãƒãƒƒãƒæ•° |
|-----------|----------------|-------------------|----------------|---------|
| 1-100     | 25             | ~50MB             | <30ç§’          | 1-4     |
| 100-500   | 50             | ~250MB            | 1-2åˆ†          | 2-10    |
| 500-1000  | 100            | ~500MB            | 2-5åˆ†          | 5-10    |
| 1000-2000 | 200            | ~1GB              | 5-10åˆ†         | 5-10    |

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

```mermaid
graph LR
    subgraph "ã‚³ãƒ¼ãƒ‰é‡"
        A1[Before: 3000è¡Œ] --> A2[After: 10è¡Œ]
    end
    
    subgraph "ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹"
        B1[Before: æ‰‹å‹•ä¿®æ­£] --> B2[After: è‡ªå‹•æ¤œå‡º]
    end
    
    subgraph "ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£"
        C1[Before: 3ãƒ†ãƒŠãƒ³ãƒˆå›ºå®š] --> C2[After: ç„¡åˆ¶é™]
    end
    
    subgraph "å‡¦ç†æ™‚é–“"
        D1[Before: éåŠ¹ç‡] --> D2[After: ãƒãƒƒãƒæœ€é©åŒ–]
    end
    
    style A2 fill:#ccffcc
    style B2 fill:#ccffcc
    style C2 fill:#ccffcc
    style D2 fill:#ccffcc
```

### å®Ÿè¡Œæ™‚é–“ã®ç›®å®‰

#### ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ

| ãƒ†ãƒŠãƒ³ãƒˆæ•° | ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ | dbt parse | dbt run | åˆè¨ˆæ™‚é–“ |
|-----------|------------|-----------|---------|----------|
| 3         | <1ç§’       | 2-3ç§’     | 5-10ç§’   | <15ç§’    |
| 10        | 1-2ç§’      | 2-3ç§’     | 10-15ç§’  | <20ç§’    |
| 50        | 5-10ç§’     | 3-5ç§’     | 30-60ç§’  | 1-2åˆ†    |
| 100       | 10-20ç§’    | 5-10ç§’    | 1-3åˆ†    | 2-5åˆ†    |

#### AWSç’°å¢ƒ

| ãƒ†ãƒŠãƒ³ãƒˆæ•° | dbtç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— | dbtãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œ | dbtãƒ†ã‚¹ãƒˆ | åˆè¨ˆæ™‚é–“ |
|-----------|-------------------|--------------|----------|----------|
| 3         | 30-40ç§’           | 10-20ç§’      | 5-10ç§’   | 1åˆ†      |
| 100       | 30-40ç§’           | 1-2åˆ†        | 10-20ç§’  | 2-3åˆ†    |
| 1000      | 30-40ç§’           | 5-10åˆ†       | 30-60ç§’  | 6-12åˆ†   |

---

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ä¸€èˆ¬çš„ãªå•é¡Œã¨è§£æ±ºç­–

#### 1. ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶:**
```
ERROR: out of memory
```

**è§£æ±ºç­–:**
```yaml
# dbt_project.yml ã§ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹
tenant_processing:
  batch_size: 25  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ50ã‹ã‚‰å‰Šæ¸›
```

#### 2. ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

**ç—‡çŠ¶:**
```
ERROR: query timeout exceeded
```

**è§£æ±ºç­–:**
```yaml
# ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“ã‚’å»¶é•·
performance:
  query_timeout_seconds: 7200  # 2æ™‚é–“ã«å»¶é•·
```

#### 3. ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ: Docker ã‚³ãƒ³ãƒ†ãƒŠãŒèµ·å‹•ã—ãªã„

**ç—‡çŠ¶:**
```
ERROR: dbt-local container is not running
```

**è§£æ±ºç­–:**
```bash
# Dockerç’°å¢ƒã‚’èµ·å‹•
docker compose up -d

# ã‚³ãƒ³ãƒ†ãƒŠã®çŠ¶æ…‹ç¢ºèª
docker compose ps

# ãƒ­ã‚°ç¢ºèª
docker compose logs dbt-local
```

#### 4. AWSç’°å¢ƒ: Bastion Hostæ¥ç¶šã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶:**
```
ERROR: Bastion Host stack not found
```

**è§£æ±ºç­–:**
```bash
# Phase 1ãŒå®Œäº†ã—ã¦ã„ã‚‹ã‹ç¢ºèª
./1-etl-manager.sh -p aurora-postgresql -c config.json

# CloudFormationã‚¹ã‚¿ãƒƒã‚¯ã®ç¢ºèª
aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE
```

#### 5. dbt parse ã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶:**
```
ERROR: Compilation Error in macro
```

**è§£æ±ºç­–:**
```bash
# ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ
docker compose exec dbt-local dbt debug
docker compose exec dbt-local dbt parse --verbose

# AWSç’°å¢ƒ
./4-etl-manager.sh -p aurora-postgresql -c config.json --bastion-command "scripts/4-dbt-execute.sh config.json 'dbt debug'"
```

#### 6. é–‹ç™ºæ™‚ã®é«˜é€ŸåŒ–

**ç—‡çŠ¶:**
å‡¦ç†ã«æ™‚é–“ãŒã‹ã‹ã‚Šã™ãã‚‹

**è§£æ±ºç­–:**
```yaml
# ãƒ†ãƒŠãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
tenant_processing:
  enable_tenant_filter: true
  filtered_tenants: ["tenant_a", "tenant_b"]
```

#### 7. ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

```bash
# å…¨ã‚³ãƒ³ãƒ†ãƒŠã¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®å‰Šé™¤
docker compose down -v

# å†èµ·å‹•
docker compose up -d
```

### Phase 4æ–°æ©Ÿèƒ½ï¼šçµ±ä¸€èªè¨¼ã‚·ã‚¹ãƒ†ãƒ 

#### **4-sql-execute.sh ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**

Phase 4å°‚ç”¨ã®SQLå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã€ä»–ã®ãƒ•ã‚§ãƒ¼ã‚ºã¨çµ±ä¸€ã—ãŸèªè¨¼æƒ…å ±ç®¡ç†ã‚’å®Ÿç¾ï¼š

**ä¸»ãªç‰¹å¾´:**
- **çµ±ä¸€èªè¨¼**: `bastion-redshift-connection.json`ã‹ã‚‰ã®è‡ªå‹•èªè¨¼æƒ…å ±èª­ã¿è¾¼ã¿
- **Phaseæ¤œå‡º**: SQLãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰è‡ªå‹•çš„ã«é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’é¸æŠ
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å®Œå…¨æ’é™¤
- **Phase 4æœ€é©åŒ–**: dbtä½œæˆãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ç”¨ã«`dev`ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’è‡ªå‹•é¸æŠ

**ä½¿ç”¨ä¾‹:**
```bash
# åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•
./4-etl-manager.sh -p aurora-postgresql -c config.json --bastion-command "scripts/4-sql-execute.sh config.json sql/redshift/verification/verify-zero-etl-all-users.sql"

# é«˜é€Ÿå®Ÿè¡Œï¼ˆãƒ•ã‚¡ã‚¤ãƒ«è»¢é€ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
./4-etl-manager.sh -p aurora-postgresql -c config.json --skip-copy --bastion-command "scripts/4-sql-execute.sh config.json sql/redshift/verification/verify-zero-etl-all-users.sql"
```

---

## ğŸ“ˆ ç›£è¦–ã¨ãƒ­ã‚°

### å‡¦ç†çµ±è¨ˆã®ç¢ºèª

ãƒã‚¯ãƒ­å®Ÿè¡Œæ™‚ã«ä»¥ä¸‹ã®çµ±è¨ˆãŒå‡ºåŠ›ã•ã‚Œã¾ã™ï¼š

```
=== Tenant Processing Stats ===
Table: users
Total Tenants: 847
Batch Size: 100
Batch Count: 9
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–

```bash
# ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ
./4-etl-manager.sh -p aurora-postgresql -c config.json --local --bastion-command "dbt run-operation estimate_processing_time --args '{tenant_count: 100, avg_rows_per_tenant: 1000}'"

# AWSç’°å¢ƒ
./4-etl-manager.sh -p aurora-postgresql -c config.json --bastion-command "scripts/4-dbt-execute.sh config.json 'dbt run-operation estimate_processing_time --args \"{tenant_count: 1000, avg_rows_per_tenant: 5000}\"'"
```

---

## ğŸ”® ä»Šå¾Œã®æ‹¡å¼µå¯èƒ½æ€§

### ãƒ•ã‚§ãƒ¼ã‚º6ï¼ˆå°†æ¥è¨ˆç”»ï¼‰

```mermaid
graph TB
    A[ç¾åœ¨ã®å®Ÿè£…] --> B[è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°]
    A --> C[ä¸¦åˆ—å‡¦ç†]
    A --> D[ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½]
    A --> E[ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰]
    
    B --> F[ãƒ†ãƒŠãƒ³ãƒˆæ•°ã«å¿œã˜ãŸ<br/>å‹•çš„ãƒãƒƒãƒã‚µã‚¤ã‚ºèª¿æ•´]
    C --> G[è¤‡æ•°ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ã®<br/>ä¸¦åˆ—å®Ÿè¡Œ]
    D --> H[ãƒ†ãƒŠãƒ³ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®<br/>ã‚­ãƒ£ãƒƒã‚·ãƒ¥]
    E --> I[ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ <br/>å‡¦ç†ç›£è¦–]
    
    style A fill:#ccffcc
    style B fill:#e1f5ff
    style C fill:#e1f5ff
    style D fill:#e1f5ff
    style E fill:#e1f5ff
```

1. **è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**: ãƒ†ãƒŠãƒ³ãƒˆæ•°ã«å¿œã˜ãŸå‹•çš„ãƒãƒƒãƒã‚µã‚¤ã‚ºèª¿æ•´
2. **ä¸¦åˆ—å‡¦ç†**: è¤‡æ•°ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ã®ä¸¦åˆ—å®Ÿè¡Œ
3. **ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½**: ãƒ†ãƒŠãƒ³ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
4. **ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ç›£è¦–

---

## ğŸ“ ã¾ã¨ã‚

ã“ã®æœ€é©åŒ–ã«ã‚ˆã‚Šã€ä»¥ä¸‹ã‚’å®Ÿç¾ã—ã¾ã—ãŸï¼š

### âœ… é”æˆã—ãŸæˆæœ

| é …ç›® | Before | After | æ”¹å–„ç‡ |
|------|--------|-------|--------|
| **ã‚³ãƒ¼ãƒ‰é‡** | 3000è¡Œ | 10è¡Œ | 99.7%å‰Šæ¸› |
| **ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹** | æ‰‹å‹•ä¿®æ­£å¿…é ˆ | è‡ªå‹•æ¤œå‡º | 100%è‡ªå‹•åŒ– |
| **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£** | 3ãƒ†ãƒŠãƒ³ãƒˆå›ºå®š | ç„¡åˆ¶é™ | âˆ |
| **å‡¦ç†åŠ¹ç‡** | éæœ€é©åŒ– | ãƒãƒƒãƒæœ€é©åŒ– | 10å€å‘ä¸Š |
| **é–‹ç™ºç’°å¢ƒ** | ãªã— | Dockerå¯¾å¿œ | æ–°è¦è¿½åŠ  |

### ğŸ¯ ä¸»è¦æ©Ÿèƒ½

âœ… **å®Œå…¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«**: 1000+ãƒ†ãƒŠãƒ³ãƒˆå¯¾å¿œ  
âœ… **ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ•ãƒªãƒ¼**: æ–°ãƒ†ãƒŠãƒ³ãƒˆè‡ªå‹•æ¤œå‡º  
âœ… **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**: ãƒãƒƒãƒå‡¦ç†ã¨ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–  
âœ… **é–‹ç™ºè€…ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼**: ãƒ­ãƒ¼ã‚«ãƒ«/ãƒªãƒ¢ãƒ¼ãƒˆçµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹  
âœ… **ç›£è¦–æ©Ÿèƒ½**: è©³ç´°ãªãƒ­ã‚°ã¨çµ±è¨ˆ  
âœ… **ãƒ†ã‚¹ãƒˆå¯¾å¿œ**: è‡ªå‹•ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ  

### ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. æœ¬ç•ªç’°å¢ƒã§ã®ãƒ‡ãƒ—ãƒ­ã‚¤
2. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã®å®Ÿè£…
3. è¿½åŠ ã®ãƒã‚¯ãƒ­é–‹ç™º
4. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç¶™ç¶šçš„ãªæ›´æ–°
5. BI Toolçµ±åˆï¼ˆTableau, QuickSight, Lookerï¼‰

### ğŸ’¡ å®Ÿè£…ã®é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

#### 1. **æœ¬æ ¼dbtãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**
å˜ç´”ãªSQLãƒ“ãƒ¥ãƒ¼ã§ã¯ãªãã€å®Œå…¨ãªdbtãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã¨ãƒãƒ†ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³

#### 2. **çµ±ä¸€èªè¨¼æƒ…å ±ç®¡ç†**
å…¨ãƒ•ã‚§ãƒ¼ã‚ºã§ä¸€è²«ã—ãŸèªè¨¼æƒ…å ±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ€§ã‚’å‘ä¸Š

#### 3. **ãƒ­ãƒ¼ã‚«ãƒ«/ãƒªãƒ¢ãƒ¼ãƒˆçµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹**
`--local`ãƒ•ãƒ©ã‚°1ã¤ã§ãƒ­ãƒ¼ã‚«ãƒ«Dockerç’°å¢ƒã¨AWSç’°å¢ƒã‚’åˆ‡ã‚Šæ›¿ãˆå¯èƒ½

#### 4. **Zero-ETLå¤–éƒ¨ãƒ†ãƒ¼ãƒ–ãƒ«å¯¾å¿œ**
Redshiftã®å¤–éƒ¨ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¶é™ã‚’ç†è§£ã—ã€é©åˆ‡ãªãƒ†ãƒ¼ãƒ–ãƒ«ãƒãƒ†ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã§å›é¿

#### 5. **ä¾å­˜é–¢ä¿‚ç®¡ç†**
dbt-redshiftã€redshift-connectorã€gitã®æ­£ç¢ºãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†

å¾“æ¥ã®3ãƒ†ãƒŠãƒ³ãƒˆå›ºå®šã‹ã‚‰ã€å®Ÿè³ªç„¡åˆ¶é™ã®ãƒ†ãƒŠãƒ³ãƒˆæ•°ã«å¯¾å¿œã™ã‚‹ã€çœŸã«ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªETLã‚·ã‚¹ãƒ†ãƒ ãŒå®Œæˆã—ã¾ã—ãŸã€‚